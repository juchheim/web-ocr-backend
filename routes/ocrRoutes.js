import express from 'express';
import upload from '../middlewares/multerConfig.js';
import { protect as protectRoute } from './auth.js'; // Import the protect middleware
import rateLimit from 'express-rate-limit'; // Import express-rate-limit

// Rate limiter for image processing route
const imageProcessingLimiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 300, // Limit each IP to 300 requests per windowMs
    standardHeaders: true, // Return rate limit info in the `RateLimit-*` headers
    legacyHeaders: false, // Disable the `X-RateLimit-*` headers
    message: 'Too many image processing requests from this IP, please try again after 15 minutes'
});

// Helper function to generate the asset URL
function generateAssetUrl(assetTagString, region = 'HC') {
  if (!assetTagString || typeof assetTagString !== 'string') {
    return null;
  }
  const trimmedTag = assetTagString.trim();
  // Ensure the trimmed tag is not empty and consists only of digits
  if (trimmedTag === '' || !/^\d+$/.test(trimmedTag)) {
    return null;
  }

  // ParseInt will handle leading zeros correctly for normalization (e.g., "00123" -> 123)
  const numericValue = parseInt(trimmedTag, 10);

  // This check is mostly redundant due to the regex, but good for absolute safety with parseInt behavior
  if (isNaN(numericValue)) {
     return null;
  }

  const normalizedForPadding = String(numericValue); // Convert back to string for padding

  // Determine base domain based on region
  const baseDomain = region === 'YC' ? 'yazoo' : 'humphreys';
  const baseUrl = `https://${baseDomain}.camarathon.net/MarathonWeb/FA/Activities/Assets/AssetMain.aspx?FormAction=Edit&AssetNo=`;
  const paddedTag = normalizedForPadding.padStart(12, '0'); // Pad to 12 digits
  return `${baseUrl}${paddedTag}&SortGrid=AssetNo&ItemFilterID=170851`;
}

// This function accepts the openai client and db instance as arguments
export default function createOcrRoutes(openai, db) {
  const router = express.Router();

  // Apply protectRoute middleware and the new rate limiter before the multer upload and the main route handler
  router.post('/extract-text', imageProcessingLimiter, protectRoute, upload.array('photos', 50), async (req, res) => {
    // The req.user object will be available here if authentication is successful
    const { id: userId, email: userEmail } = req.user;
    const { assetTag: manualAssetTag, assetUrl: manualAssetUrl, roomNumber: roomNumberFromBody, captureDetail, sourceImageOriginalName, region: regionFromBody } = req.body;

    // Default region to HC if not provided
    const region = regionFromBody || 'HC';

    // Handle Manual Entry
    if (sourceImageOriginalName === 'manual_entry' && manualAssetTag && manualAssetUrl) {
      try {
        const assetTagsCollection = db.collection('asset_tags');
        const docToInsert = {
          assetTag: manualAssetTag.trim(),
          assetUrl: manualAssetUrl.trim(), // URL is pre-generated by frontend
          scannedAt: new Date(),
          sourceImageOriginalName: 'manual_entry',
          userId: userId,
          userEmail: userEmail,
        };

        if (roomNumberFromBody) {
          docToInsert.roomNumber = roomNumberFromBody.trim();
        }
        // Optionally save captureDetail for manual entries if needed
        // if (captureDetail) {
        //   docToInsert.captureDetail = captureDetail;
        // }

        const result = await assetTagsCollection.insertOne(docToInsert);
        let logMessage = `Manual asset tag '${docToInsert.assetTag}' (URL: ${docToInsert.assetUrl})`;
        if (docToInsert.roomNumber) {
          logMessage += ` for room '${docToInsert.roomNumber}'`;
        }
        logMessage += ` saved to MongoDB with id: ${result.insertedId}`;
        console.log(logMessage);

        return res.json({ 
          texts: [docToInsert.assetTag], // For consistency with OCR response structure
          assetTag: docToInsert.assetTag  // To match frontend expectation for manual save
        });

      } catch (dbErr) {
        console.error("Error saving manual asset tag to MongoDB:", dbErr);
        return res.status(500).json({ error: 'Failed to save manual asset tag.', details: dbErr.message });
      }
    }

    // --- Existing OCR Logic for Photo Uploads ---
    if (!req.files?.length) {
      // This case should ideally not be reached if manual entry is handled above and frontend ensures one or the other
      return res.status(400).json({ error: 'No photos uploaded and not a valid manual entry.' });
    }

    const allExtractedTexts = [];
    let hadError = false;

    for (const file of req.files) {
      try {
        const base64 = file.buffer.toString('base64');
        const dataUrl = `data:${file.mimetype};base64,${base64}`;
        
        // Get capture detail from request body, default to 'low' if not provided or invalid
        const requestedDetail = req.body.captureDetail;
        // Map 'veryHigh' to 'high' for OpenAI, otherwise use 'low' or 'high' directly. Default to 'auto' if invalid.
        const imageDetail = (requestedDetail === 'high' || requestedDetail === 'veryHigh') ? 'high' : (requestedDetail === 'low' ? 'low' : 'auto');

        const imagePayload = [{ type: 'image_url', image_url: { url: dataUrl, detail: imageDetail } }];

        const openAiPayload = {
          model: 'gpt-4.1-nano',
          max_tokens: 2048, // Max tokens per image analysis
          temperature: 0, // Deterministic output
          messages: [
            {
              role: 'user',
              content: [
                { type: 'text', text: 'You are an OCR reader looking for a 5 digit number. This 5 digit number may have additional leading zeros. A leading zero is a zero that comes before the 5 digits and does not count as a digit. Return only the 5 digits, truncating the leading zeros. Do not return anything other than 5 digits. If there is no visible 5 digit number, return NULL' },
                ...imagePayload, // Send only one image at a time
              ],
            },
          ],
        };

        console.log(`Processing one image. Using OpenAI model: ${openAiPayload.model}`);
        // console.log('Sending one image to OpenAI:', JSON.stringify(openAiPayload, null, 2)); // Can be verbose for multiple images

        const completion = await openai.chat.completions.create(openAiPayload);
        const assetTagFromAI = completion.choices?.[0]?.message?.content || ''; // Get raw response
        allExtractedTexts.push(assetTagFromAI.trim()); // Add trimmed version to results for frontend

        let potentialAssetTag = assetTagFromAI.trim(); // This is what AI returned, trimmed
        // Aggressively remove any quote characters (single or double) that the AI might have added
        potentialAssetTag = potentialAssetTag.replace(/[\"\']/g, '').trim();

        const captureDetailFromRequest = req.body.captureDetail; // Use this for storing

        if (potentialAssetTag !== '') { // Only attempt to process if AI returned some non-empty (after trim and quote removal) text
          const assetUrl = generateAssetUrl(potentialAssetTag, region); // Pass region to generateAssetUrl

          if (assetUrl) { // If URL is successfully generated, it means potentialAssetTag was a valid numeric string
            try {
              const assetTagsCollection = db.collection('asset_tags');
              const docToInsert = {
                assetTag: potentialAssetTag, // Store the numeric string as captured (and trimmed)
                assetUrl: assetUrl, // Store the generated URL
                scannedAt: new Date(),
                sourceImageOriginalName: file.originalname, // Optional: store original filename
                userId: userId, // Associate with the logged-in user (destructured above)
                userEmail: userEmail, // Store user's email for convenience (destructured above)
                region: region, // Store selected region
              };

              if (roomNumberFromBody) {
                docToInsert.roomNumber = roomNumberFromBody.trim(); // ensure it's trimmed
              }
              if (captureDetailFromRequest) { // Store captureDetail from OCR process
                docToInsert.captureDetail = captureDetailFromRequest;
              }

              const result = await assetTagsCollection.insertOne(docToInsert);
              let logMessage = `Asset tag '${potentialAssetTag}' (URL: ${assetUrl})`;
              if (roomNumberFromBody) {
                logMessage += ` for room '${roomNumberFromBody}'`;
              }
              logMessage += ` from image '${file.originalname || 'unknown'}' saved to MongoDB with id: ${result.insertedId}`;
              console.log(logMessage);
            } catch (dbErr) {
              console.error("Error saving asset tag to MongoDB:", dbErr);
              // Continue processing other images even if one DB save fails
            }
          } else {
            // assetUrl is null, meaning potentialAssetTag was not a valid numeric asset tag string (e.g., "No tag found")
            console.log(`Skipping save for invalid or non-numeric asset tag: '${potentialAssetTag}' from image '${file.originalname || 'unknown'}'`);
          }
        } // If potentialAssetTag was empty (AI returned empty or whitespace), it's correctly skipped
      } catch (err) {
        console.error(`Error processing image ${file.originalname || 'unknown'}:`, err);
        allExtractedTexts.push(''); // Push empty string for failed image processing
        hadError = true; // Mark that at least one error occurred
        // We continue to the next image
      }
    }

    if (hadError && allExtractedTexts.every(text => text === '')) {
        // If all images resulted in an error or no text, return a general error
        return res.status(500).json({ error: 'Failed to process any images or extract text from them.', texts: allExtractedTexts });
    }

    res.json({ texts: allExtractedTexts }); // Return array of texts
  });

  return router;
} 